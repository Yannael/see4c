{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"See4C.png\", width=150, ALIGN=\"left\", border=20>\n",
    "<center>\n",
    "<h1>See.4C Video Forecasting Starting Kit</h1>\n",
    "<br>This starting kit was tested with Anaconda Python 2.7\n",
    "</center>\n",
    "<p><br><br><br>\n",
    "ALL INFORMATION, SOFTWARE, DOCUMENTATION, AND DATA ARE PROVIDED \"AS-IS\". The SEE.4C CONSORTIUM, AND/OR OTHER ORGANIZERS OR CODE AUTHORS DISCLAIM ANY EXPRESSED OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR ANY PARTICULAR PURPOSE, AND THE WARRANTY OF NON-INFRIGEMENT OF ANY THIRD PARTY'S INTELLECTUAL PROPERTY RIGHTS. IN NO EVENT SHALL AUTHORS AND ORGANIZERS BE LIABLE FOR ANY SPECIAL INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF SOFTWARE, DOCUMENTS, MATERIALS, PUBLICATIONS, OR INFORMATION MADE AVAILABLE FOR THE CHALLENGE.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where to find Sample Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os, sys\n",
    "root_dir = '.' # We assume that you are running this example where you originally found it.\n",
    "code_dir = os.path.join(root_dir, 'sample_code')\n",
    "sys.path.append(code_dir)\n",
    "cache_dir = os.path.join(root_dir, 'cache')\n",
    "from data_io import mkdir\n",
    "mkdir(cache_dir) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide a few classes and function in the sample_code directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for (path, dirs, files) in os.walk(code_dir): print [file for file in files if file.endswith('.py')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where to find Sample Data\n",
    "Data are stored in this example like on the See.4C server (where your code submission are evaluated) in two subdirectories \"train\" and \"adapt\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_dir = os.path.join(root_dir, 'sample_data')\n",
    "for (path, dirs, files) in os.walk(data_dir): print path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"train\" directory contains sub-directories named \"Xmn\", where \"n\" is a number that can range from 1 to 4 (in the sample_data n=1 or n=2).                                    \n",
    "`In the sample data we provide with the starting kit you get only:\n",
    "    Xm1 = sample data,\n",
    "In the feedback phase, you will get more:\n",
    "    Xm2 = \"public\" data,\n",
    "    Xm1 = \"feedback_train\" data. \n",
    "In the validation phase, you will get yet more:\n",
    "    Xm4 = \"public\" data,\n",
    "    Xm3 = \"feedback_train\" data,\n",
    "    Xm2 = \"feedback_adapt\" data,\n",
    "    Xm1 = \"validation_train\" data.`                    \n",
    "In each directory, video clips are stored in the hdf5 format as Xp.h5, where p is the clip number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The DataManager object\n",
    "The DataManager class allows you to painlessly load video clips into an object, as numpy arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load one video clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from data_manager import DataManager \n",
    "cache_file = os.path.join(cache_dir, \"DM.pickle\") #  This will allow faster reload\n",
    "DM = DataManager(data_file = 'sample_data/adapt/X0.h5', verbose=True, cache_file=cache_file) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also just construct a DM with `DM =  DataManager()`, then call `DM.loadData(data_file = 'xxx')`.\n",
    "\n",
    "DM contains 2 attributes: \n",
    "    - X: ndarray representing an array of frames; frames are gray level images of dim 32x32.\n",
    "    - t: ndarray representing the time index (a positive integer)\n",
    "This command just loaded a single video clip of 101 frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print type(DM.X), DM.X.shape\n",
    "print type(DM.t), DM.t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and reload data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "You can save your DataManager object to a \"pickle\" or \"h5\" file format. The parameter \"frames\" allows you to specify the frames you want to save. For example, save the first 20 frames on pickle format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from data_io import mkdir\n",
    "mkdir('temp')\n",
    "DM.saveData(data_file='temp/first_20', format='pickle', frames=(0, 20)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might want to reload your DataManager object that you have saved before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DM.reloadData(filename=os.path.join('temp', 'first_20.pickle'))\n",
    "print DM.X.shape\n",
    "print DM.t.shape\n",
    "import shutil # Cleanup\n",
    "shutil.rmtree('temp', ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading a single file is mainly useful if you want perform predictions using a single video clip, but you can do more!\n",
    "\n",
    "### Load the whole training dataset\n",
    "For training, you can load the entire training set. Note that this command erases previously loaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data_dir = os.path.join(data_dir, 'train')\n",
    "DM.loadTrainData(train_data_dir)\n",
    "print DM.X.shape\n",
    "print DM.t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append more data\n",
    "After loading the training data X, you can append to X some additional data from the \"adapt\" directory. Your preditions program will be expected to make prediction on data from the \"adapt\" directory, which will become available progressively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adapt_data_dir = os.path.join(data_dir, 'adapt')\n",
    "DM.appendSamples(data_file=\"X0\", data_dir=adapt_data_dir) # append adapt/X0.h5 to X\n",
    "print DM.X.shape\n",
    "print DM.t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the data\n",
    "\n",
    "DataManager object also provides methods to help you visualize the data. For example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DM.display(start=0, end=625, step=125) # display the first fram of each video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DM.display(start=420, end=490, step=5) # display every five frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also wrote a function that lets you see the progression of image differences, overlaid.\n",
    "    * tau: monitors the memory of past images, the larger, the more you look in the past.\n",
    "    * d: monitors the sensitivity to motion, the smaller, the most sensitive. \n",
    "The most recent motion is in red. The oldest is in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DM.motion_history_image(start=420, end=490, step=5, tau=20, d=0.05) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Practically, you have to predict 8 frames into the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DM.display(start=450) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DM.display(start=451, end=458, step=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time index may be used to determine the cuts between videos. Note that the chunks of frames in \"train\" data are of size 125 and in \"adapt\" data, they follow the sequence:\n",
    "101, 8, 8, 109, 8, 8, 109, 8, 8, 109, 8, 8, 109, etc. All videos have 125 frames. So there is a cut after the eighth frame in chunks of size 109."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DM.loadTrainData(train_data_dir)\n",
    "for i in range(10):\n",
    "    DM.appendSamples(i, data_dir=adapt_data_dir) \n",
    "import matplotlib.pyplot as plt\n",
    "fnum = min(len(DM.t), 1000)\n",
    "plt.plot(DM.t[1:fnum])\n",
    "plt.xlabel('Frame number')\n",
    "plt.ylabel('Time index (1/25 sec)')\n",
    "plt.title(\"Found %d video clips in the first %d frames\" % (list(DM.t[1:fnum]).count(0), fnum))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, Adapt, and Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are ready to write your code. Use *model.py* as a template. It has three main functions, \"train\", \"adapt\", and \"predict\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from model import Model\n",
    "Model??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "Load the entire training set and train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M = Model(verbose=True) # No hyper-parameter here, this model just implements persistence :-)\n",
    "DM.loadTrainData(train_data_dir)\n",
    "M.train(DM.X, DM.t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adapt\n",
    "Add a few more frames and adapt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DM.appendSamples(data_file=\"X0\", data_dir=adapt_data_dir)\n",
    "M.adapt(DM.X, DM.t) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n",
    "Predict the next 8 frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    RESULT = DataManager()\n",
    "    RESULT.X = M.predict(DM.X, num_predicted_frames=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RESULT.display(start=0, end=7, step=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute your Accuracy\n",
    "Prediction accuracy is computed using the RMSE. You can load the next chunk and see whether your predictions are accurate. On the server, when your code is tested, the next chunk is released only when you have made your predictions for the next 8 frames based on previously released data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from libscores import mse\n",
    "DM.appendSamples(data_file=\"X1\", data_dir=adapt_data_dir) # Get the next chunk\n",
    "frame_num=8\n",
    "solution = DM.X[-frame_num:].ravel()\n",
    "prediction = RESULT.X.ravel()\n",
    "print (\"RMSE = %5.2f\" % np.sqrt(mse(solution, prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand the data organization\n",
    "The expected sequence of query and answer videos will be:\n",
    "<pre>\n",
    "input name : number of frames    output name : number of frames\n",
    "\n",
    "X0.h5 : 101 frames               Y0.h5   :   8 frames\n",
    "X1.h5 : 8 frames                 Y1.h5   :   8 frames\n",
    "X2.h5 : 8 frames                 Y2.h5   :   8 frames\n",
    "X3.h5 : 109 frames               Y3.h5   :   8 frames\n",
    "X4.h5 : 8 frames                 Y4.h5   :   8 frames\n",
    "X5.h5 : 8 frames                 Y5.h5   :   8 frames\n",
    "X6.h5 : 109 frames               Y6.h5   :   8 frames     \n",
    "...\n",
    "X599.h5 \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare your Submission\n",
    "\n",
    "## Unit testing\n",
    "It is <b><span style=\"color:red\">important that you test your submission files before submitting them</span></b>. All you have to do to make a submission is modify the file <code>model.py</code> in the <code>sample_code/</code> directory, then run this test to make sure everything works fine. The first argument is the \"step\", try at least two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_dir = os.path.join(root_dir, 'results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!python predictSpatioTemporal.py 0 $data_dir $out_dir $root_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!python predictSpatioTemporal.py 1 $data_dir $out_dir $root_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making your Submission\n",
    "\n",
    "Zip your code, including the <span style=\"color:red\">sample_code/</span> directory, and the two scripts <span style=\"color:red\">predictSpatioTemporal.py</span> and <span style=\"color:red\">predict.sh</span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from data_io import zip_submission\n",
    "the_date = datetime.datetime.now().strftime(\"%y-%m-%d-%H-%M\")\n",
    "submission_filename = '../sample_submission_' + the_date + '.zip'\n",
    "zip_submission(submission_filename, root_dir)\n",
    "print(\"Submit the file: \" + submission_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
